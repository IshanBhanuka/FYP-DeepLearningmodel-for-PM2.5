{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "oFkS-7PAk2hk"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import r2_score as rSquared\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/FYP/CNN_trainset.pkl','rb') as f:\n",
        "    train = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/FYP/CNN_testset.pkl','rb') as f:\n",
        "    test = pickle.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjm8Q8ZTk8-W",
        "outputId": "8e21aa6f-e24b-4c41-a014-5b65b50ec8e3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "eTtnJHc9k8xO",
        "outputId": "8364517b-53ec-44cf-8f2d-4451b86701d4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-60befaec3cfe>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Assuming 'images' is your array of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Use the .flow() method to apply the scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mscaled_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[0]"
      ],
      "metadata": {
        "id": "Idbj7DJAk8uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size=224\n",
        "X_train2 = np.array([item[0] for item in train]).reshape(-1,image_size,image_size,3)\n",
        "X_test2 = np.array([item[0] for item in test]).reshape(-1,image_size,image_size,3)\n",
        "y_train = np.array([item[1] for item in train]).reshape(-1)\n",
        "y_test = np.array([item[1] for item in test]).reshape(-1)"
      ],
      "metadata": {
        "id": "7ZS3vYgzk8r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an instance of ImageDataGenerator with rescaling\n",
        "datagen1 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Assuming 'images' is your array of images\n",
        "# Use the .flow() method to apply the scaling\n",
        "X_train = datagen1.flow(X_train2)\n",
        "\n",
        "\n",
        "datagen2 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Assuming 'images' is your array of images\n",
        "# Use the .flow() method to apply the scaling\n",
        "X_test = datagen2.flow(X_test2)\n"
      ],
      "metadata": {
        "id": "chVW-Sozk8pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  layers.Conv2D(8, (4, 4), padding='same', activation='relu', input_shape=(224, 224, 3)),\n",
        "  layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "  layers.Conv2D(16, (4, 4), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "  layers.Conv2D(32,  (2, 2), padding='same', activation='relu'),\n",
        "  layers.Conv2D(64,  (2, 2), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "  layers.Conv2D(128,  (2, 2), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "  layers.Conv2D(256,  (2, 2), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "  layers.Conv2D(256, (2, 2), padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(1, activation='linear'),\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "yfq6EnX1k8mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mae',optimizer='Adam')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=35, verbose=1)"
      ],
      "metadata": {
        "id": "dFUsqdF_k8hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochsize = 300\n",
        "#model = model.fit(X_train, y_train, validation_split= 0.1,epochs=10, batch_size = 100, callbacks=[early_stop],verbose= 1,shuffle=False)\n",
        "history = model.fit(X_train, y_train, validation_split= 0.1,epochs=epochsize, batch_size=100, callbacks=[early_stop],verbose= 1,shuffle=False)"
      ],
      "metadata": {
        "id": "moYO9Pg2k8Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.evaluate(X_test, y_test)\n",
        "#accuracy = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "oX-5D7vDk8Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_yROk3U-vn2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "URM6dtj4k7_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
        "\n",
        "y_pred1 = model.predict(X_test)\n",
        "y_pred = y_pred1.reshape(-1)\n",
        "MAE=mae(y_test,y_pred)\n",
        "RMSE=mse(y_test,y_pred,squared=False)\n",
        "MAPE=mape(y_test,y_pred)\n",
        "R2=rSquared(y_test,y_pred)\n",
        "\n",
        "print(\"Mean Absolute Error:\", MAE)\n",
        "print(\"Root Mean Squared Error:\", RMSE)\n",
        "print(\"Mean Absolute Precentage Error\",MAPE)\n",
        "print(\"Coefficient of determination \",R2)"
      ],
      "metadata": {
        "id": "61aPRlMPk78h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "x=datetime.datetime.now()\n",
        "model_name=(\"{}_{}_{}_{}.hdf5\".format(x.month,x.day,x.hour,x.minute))\n",
        "\n",
        "model.save('/content/drive/MyDrive/FYP/saved_models/saved_CNN_models/'+model_name)"
      ],
      "metadata": {
        "id": "qCO1eCiEk75t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plotting y_test values\n",
        "plt.scatter(y_pred, y_test, c='blue', label='True Values')\n",
        "\n",
        "max_value = max(max(y_test), max(y_pred))\n",
        "min_value = min(min(y_test), min(y_pred))\n",
        "plt.plot([min_value, max_value], [min_value, max_value], color='red',linestyle='dashed',label='Reference line')\n",
        "\n",
        "\n",
        "plt.xlabel('Predicted PM2.5 values (ug/m3)', fontsize=15)\n",
        "plt.ylabel('True PM2.5 values (ug/m3)', fontsize=15)\n",
        "#plt.legend()\n",
        "#plt.title(\"Scatter plot of Predicted Vs True PM2.5 Concentrations\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N7rdDBOtk7wv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}